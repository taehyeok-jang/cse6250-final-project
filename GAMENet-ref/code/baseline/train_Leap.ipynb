{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dedfe87-e1b5-4d25-a817-d93a712ecdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters 436884\n",
      "Train--Epoch: 0, Step: 4232/4233\n",
      "Eval--Epoch: 0, Step: 0/1059"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 244\u001b[0m\n\u001b[1;32m    238\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    239\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal.model\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 132\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    130\u001b[0m     llprint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mTrain--Epoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Step: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, step, \u001b[38;5;28mlen\u001b[39m(data_train)))\n\u001b[0;32m--> 132\u001b[0m ddi_rate, ja, prauc, avg_p, avg_r, avg_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mja\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ja)\n\u001b[1;32m    134\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddi_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ddi_rate)\n",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, data_eval, voc_size, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m     med_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sorted_predict)\n\u001b[1;32m     56\u001b[0m records\u001b[38;5;241m.\u001b[39mappend(y_pred_label)\n\u001b[0;32m---> 58\u001b[0m adm_ja, adm_prauc, adm_avg_p, adm_avg_r, adm_avg_f1 \u001b[38;5;241m=\u001b[39m sequence_metric(np\u001b[38;5;241m.\u001b[39marray(y_gt), np\u001b[38;5;241m.\u001b[39marray(y_pred), np\u001b[38;5;241m.\u001b[39marray(y_pred_prob), \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_label\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     59\u001b[0m ja\u001b[38;5;241m.\u001b[39mappend(adm_ja)\n\u001b[1;32m     60\u001b[0m prauc\u001b[38;5;241m.\u001b[39mappend(adm_prauc)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import jaccard_score, roc_auc_score, precision_score, f1_score, average_precision_score\n",
    "import numpy as np\n",
    "import dill\n",
    "import time\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models import Leap\n",
    "from util import llprint, sequence_metric, sequence_output_process, ddi_rate_score, get_n_params\n",
    "\n",
    "torch.manual_seed(1203)\n",
    "\n",
    "model_name = 'Leap'\n",
    "resume_name = ''\n",
    "\n",
    "def eval(model, data_eval, voc_size, epoch):\n",
    "    # evaluate\n",
    "    print('')\n",
    "    model.eval()\n",
    "\n",
    "    ja, prauc, avg_p, avg_r, avg_f1 = [[] for _ in range(5)]\n",
    "    records = []\n",
    "    med_cnt = 0\n",
    "    visit_cnt = 0\n",
    "    for step, input in enumerate(data_eval):\n",
    "        y_gt = []\n",
    "        y_pred = []\n",
    "        y_pred_prob = []\n",
    "        y_pred_label = []\n",
    "        for adm in input:\n",
    "            y_gt_tmp = np.zeros(voc_size[2])\n",
    "            y_gt_tmp[adm[2]] = 1\n",
    "            y_gt.append(y_gt_tmp)\n",
    "\n",
    "            output_logits = model(adm)\n",
    "            output_logits = output_logits.detach().cpu().numpy()\n",
    "\n",
    "            out_list, sorted_predict = sequence_output_process(output_logits, [voc_size[2], voc_size[2]+1])\n",
    "\n",
    "            y_pred_label.append(sorted(sorted_predict))\n",
    "            y_pred_prob.append(np.mean(output_logits[:, :-2], axis=0))\n",
    "\n",
    "            y_pred_tmp = np.zeros(voc_size[2])\n",
    "            y_pred_tmp[out_list] = 1\n",
    "            y_pred.append(y_pred_tmp)\n",
    "            visit_cnt += 1\n",
    "            med_cnt += len(sorted_predict)\n",
    "        records.append(y_pred_label)\n",
    "\n",
    "        adm_ja, adm_prauc, adm_avg_p, adm_avg_r, adm_avg_f1 = sequence_metric(np.array(y_gt), np.array(y_pred), np.array(y_pred_prob), np.array(y_pred_label))\n",
    "        ja.append(adm_ja)\n",
    "        prauc.append(adm_prauc)\n",
    "        avg_p.append(adm_avg_p)\n",
    "        avg_r.append(adm_avg_r)\n",
    "        avg_f1.append(adm_avg_f1)\n",
    "        llprint('\\rEval--Epoch: %d, Step: %d/%d' % (epoch, step, len(data_eval)))\n",
    "\n",
    "    # ddi rate\n",
    "    ddi_rate = ddi_rate_score(records)\n",
    "    llprint('\\tDDI Rate: %.4f, Jaccard: %.4f,  PRAUC: %.4f, AVG_PRC: %.4f, AVG_RECALL: %.4f, AVG_F1: %.4f\\n' % (\n",
    "        ddi_rate, np.mean(ja), np.mean(prauc), np.mean(avg_p), np.mean(avg_r), np.mean(avg_f1)\n",
    "    ))\n",
    "    print('avg med', med_cnt / visit_cnt)\n",
    "    return ddi_rate, np.mean(ja), np.mean(prauc), np.mean(avg_p), np.mean(avg_r), np.mean(avg_f1)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(os.path.join(\"saved\", model_name)):\n",
    "        os.makedirs(os.path.join(\"saved\", model_name))\n",
    "\n",
    "    data_path = '../../data/records_final.pkl'\n",
    "    voc_path = '../../data/voc_final.pkl'\n",
    "    # device = torch.device('cuda:0')\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data = dill.load(open(data_path, 'rb'))\n",
    "    voc = dill.load(open(voc_path, 'rb'))\n",
    "    diag_voc, pro_voc, med_voc = voc['diag_voc'], voc['pro_voc'], voc['med_voc']\n",
    "\n",
    "\n",
    "    split_point = int(len(data) * 2 / 3)\n",
    "    data_train = data[:split_point]\n",
    "    eval_len = int(len(data[split_point:]) / 2)\n",
    "    data_test = data[split_point:split_point + eval_len]\n",
    "    data_eval = data[split_point+eval_len:]\n",
    "    voc_size = (len(diag_voc.idx2word), len(pro_voc.idx2word), len(med_voc.idx2word))\n",
    "\n",
    "    EPOCH = 10\n",
    "    LR = 0.0002\n",
    "    TEST = False\n",
    "    END_TOKEN = voc_size[2] + 1\n",
    "\n",
    "    model = Leap(voc_size, device=device)\n",
    "    if TEST:\n",
    "        model.load_state_dict(torch.load(open(os.path.join(\"saved\", model_name, resume_name), 'rb')))\n",
    "        # pass\n",
    "\n",
    "    model.to(device=device)\n",
    "    print('parameters', get_n_params(model))\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    if TEST:\n",
    "        eval(model, data_test, voc_size, 0)\n",
    "    else:\n",
    "        history = defaultdict(list)\n",
    "        for epoch in range(EPOCH):\n",
    "            loss_record = []\n",
    "            start_time = time.time()\n",
    "            model.train()\n",
    "            for step, input in enumerate(data_train):\n",
    "                for adm in input:\n",
    "                    loss_target = adm[2] + [END_TOKEN]\n",
    "                    output_logits = model(adm)\n",
    "                    loss = F.cross_entropy(output_logits, torch.LongTensor(loss_target).to(device))\n",
    "\n",
    "                    loss_record.append(loss.item())\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "\n",
    "                llprint('\\rTrain--Epoch: %d, Step: %d/%d' % (epoch, step, len(data_train)))\n",
    "\n",
    "            ddi_rate, ja, prauc, avg_p, avg_r, avg_f1 = eval(model, data_eval, voc_size, epoch)\n",
    "            history['ja'].append(ja)\n",
    "            history['ddi_rate'].append(ddi_rate)\n",
    "            history['avg_p'].append(avg_p)\n",
    "            history['avg_r'].append(avg_r)\n",
    "            history['avg_f1'].append(avg_f1)\n",
    "            history['prauc'].append(prauc)\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = (end_time - start_time) / 60\n",
    "            llprint('\\tEpoch: %d, Loss1: %.4f, One Epoch Time: %.2fm, Appro Left Time: %.2fh\\n' % (epoch,\n",
    "                                                                                                np.mean(loss_record),\n",
    "                                                                                                elapsed_time,\n",
    "                                                                                                elapsed_time * (\n",
    "                                                                                                            EPOCH - epoch - 1)/60))\n",
    "\n",
    "            torch.save(model.state_dict(), open( os.path.join('saved', model_name, 'Epoch_%d_JA_%.4f_DDI_%.4f.model' % (epoch, ja, ddi_rate)), 'wb'))\n",
    "            print('')\n",
    "\n",
    "        dill.dump(history, open(os.path.join('saved', model_name, 'history.pkl'), 'wb'))\n",
    "        # test\n",
    "        torch.save(model.state_dict(), open(\n",
    "            os.path.join('saved', model_name, 'final.model'), 'wb'))\n",
    "\n",
    "def fine_tune(fine_tune_name=''):\n",
    "    data_path = '../../data/records_final.pkl'\n",
    "    voc_path = '../../data/voc_final.pkl'\n",
    "    # device = torch.device('cuda:0')\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data = dill.load(open(data_path, 'rb'))\n",
    "    voc = dill.load(open(voc_path, 'rb'))\n",
    "    diag_voc, pro_voc, med_voc = voc['diag_voc'], voc['pro_voc'], voc['med_voc']\n",
    "    ddi_A = dill.load(open('../../data/ddi_A_final.pkl', 'rb'))\n",
    "\n",
    "    split_point = int(len(data) * 2 / 3)\n",
    "    data_train = data[:split_point]\n",
    "    eval_len = int(len(data[split_point:]) / 2)\n",
    "    data_test = data[split_point:split_point + eval_len]\n",
    "    # data_eval = data[split_point+eval_len:]\n",
    "    voc_size = (len(diag_voc.idx2word), len(pro_voc.idx2word), len(med_voc.idx2word))\n",
    "\n",
    "    model = Leap(voc_size, device=device)\n",
    "    model.load_state_dict(torch.load(open(os.path.join(\"saved\", model_name, fine_tune_name), 'rb')))\n",
    "    model.to(device)\n",
    "\n",
    "    EPOCH = 30\n",
    "    LR = 0.0001\n",
    "    END_TOKEN = voc_size[2] + 1\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    ddi_rate_record = []\n",
    "    for epoch in range(1):\n",
    "        loss_record = []\n",
    "        start_time = time.time()\n",
    "        random_train_set = [ random.choice(data_train) for i in range(len(data_train))]\n",
    "        for step, input in enumerate(random_train_set):\n",
    "            model.train()\n",
    "            K_flag = False\n",
    "            for adm in input:\n",
    "                target = adm[2]\n",
    "                output_logits = model(adm)\n",
    "                out_list, sorted_predict = sequence_output_process(output_logits.detach().cpu().numpy(), [voc_size[2], voc_size[2] + 1])\n",
    "\n",
    "                inter = set(out_list) & set(target)\n",
    "                union = set(out_list) | set(target)\n",
    "                jaccard = 0 if union == 0 else len(inter) / len(union)\n",
    "                K = 0\n",
    "                for i in out_list:\n",
    "                    if K == 1:\n",
    "                        K_flag = True\n",
    "                        break\n",
    "                    for j in out_list:\n",
    "                        if ddi_A[i][j] == 1:\n",
    "                            K = 1\n",
    "                            break\n",
    "\n",
    "                loss = -jaccard * K * torch.mean(F.log_softmax(output_logits, dim=-1))\n",
    "\n",
    "\n",
    "                loss_record.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "            llprint('\\rTrain--Epoch: %d, Step: %d/%d' % (epoch, step, len(data_train)))\n",
    "\n",
    "            if K_flag:\n",
    "                ddi_rate, ja, prauc, avg_p, avg_r, avg_f1 = eval(model, data_test, voc_size, epoch)\n",
    "\n",
    "\n",
    "                end_time = time.time()\n",
    "                elapsed_time = (end_time - start_time) / 60\n",
    "                llprint('\\tEpoch: %d, Loss1: %.4f, One Epoch Time: %.2fm, Appro Left Time: %.2fh\\n' % (epoch,\n",
    "                                                                                               np.mean(loss_record),\n",
    "                                                                                               elapsed_time,\n",
    "                                                                                               elapsed_time * (\n",
    "                                                                                                       EPOCH - epoch - 1) / 60))\n",
    "\n",
    "                torch.save(model.state_dict(),\n",
    "                   open(os.path.join('saved', model_name, 'fine_Epoch_%d_JA_%.4f_DDI_%.4f.model' % (epoch, ja, ddi_rate)),\n",
    "                        'wb'))\n",
    "                print('')\n",
    "\n",
    "    # test\n",
    "    torch.save(model.state_dict(), open(\n",
    "        os.path.join('saved', model_name, 'final.model'), 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    # fine_tune(fine_tune_name='Epoch_26_JA_0.4465_DDI_0.0723.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53850d1f-8916-49fe-adc9-39c5d4a5f56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
